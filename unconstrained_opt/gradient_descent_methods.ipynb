{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e562af-4a2a-4c6c-accb-60ff865ea8cd",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "1. Vanilla Gradient Descent \n",
    "2. Gradient Descent with Momentum \n",
    "3. Steepest Gradient Descent \n",
    "4. Stochastic Gradient Descent \n",
    "5. Newton's Method of Gradient Descent\n",
    "6. Quasi-Newton's Method of Gradient Descent\n",
    "\n",
    "$\\nabla$ denotes the derivative of the corresponding variable, of which it is a Hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92f435-3801-4ce4-9cc0-eaaec46798f7",
   "metadata": {},
   "source": [
    "### Vanilla Gradient Descent \n",
    "\n",
    "Put simply, gradient descent can be computed to correcting for weight estimates in a optimisation problem using the derivative of a certain error term $\\epsilon(w)$.\n",
    "\n",
    "The derivative of the gradient, given $w$, a weight vector containing well, a vector of weights, is: \n",
    "\n",
    "($\\nabla$ indicating the derivative of)\n",
    "$\\large \\nabla \\epsilon(w) = \\begin{pmatrix} \\frac {\\delta \\epsilon} {\\delta w_0} \\\\ \\frac {\\delta \\epsilon} {\\delta w_1} \\\\  . \\\\ . \\\\ . \\\\ \\frac {\\delta \\epsilon}{\\delta w_n} \\end{pmatrix} $\n",
    "\n",
    "And the training rule to converge on an optimal set of weights will be: \n",
    "\n",
    "$ w = w + \\Delta w $  where $\\Delta w = -\\eta \\nabla \\epsilon (w)$\n",
    "\n",
    "and $\\eta$ is the learning rate, a positive small value constant\n",
    "\n",
    "This is the algorithm that I used in my MLP notebook for the creation of a single node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8bd240-c666-4908-a183-5fed8d9c804a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f40dcd6d-ee65-42d7-ac78-8eca943b23c1",
   "metadata": {},
   "source": [
    "#### Gradient Descent with Momentum\n",
    "\n",
    "This is an extension to the simple gradient descent that allows the initial search to build inertia into the direction of the search space (extrema) and overcome the oscillations of noisy gradients and flat gradients in the search space.\n",
    "\n",
    "This is done by adding an additional momentum term, that \"remembers\" the previous iteration. This way, it is easier to not overshot our minima. The diagram below represents this nicely.\n",
    "\n",
    "$w = w - \\eta \\nabla \\epsilon (w) + \\alpha (w_t - w_{t - 1})$ where $\\alpha$ is the momentum parameter, and $t$ is the iteration number. $t = 0$ means initial weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf16982-045f-46bc-94d8-c3ae2f5892f7",
   "metadata": {},
   "source": [
    "<img src = \"media/gradient_descent_with_momentum.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438b418f-6fba-46c1-b91e-40f5fdebccff",
   "metadata": {},
   "source": [
    "Then as an example, assuming an error term to be minimized: \n",
    "\n",
    "$\\epsilon(w) = (w_1 - x_1)^2 + (w_2 - x_2)^2$ \n",
    "\n",
    "$\\epsilon(w) = (w_1 - 2)^2 + (w_2 - 3)^2$\n",
    "\n",
    "\n",
    "with $\\alpha = 0.5$ $\\nabla = 0.25$ and initial weights $ w_{t=0} = \\begin{pmatrix} 0 \\\\ 6 \\end{pmatrix} $ since $ t = 0 $\n",
    "\n",
    "we get\n",
    "\n",
    "$ \\nabla \\epsilon (w) = \\begin{pmatrix} {2(w_1-2)} \\\\ {2(w_2-3)} \\end{pmatrix} = \\begin{pmatrix} -4 \\\\ 4 \\end{pmatrix}$\n",
    "\n",
    "and so \n",
    "\n",
    "$ w_{t =1} =  \\begin{pmatrix} 0 \\\\ 6 \\end{pmatrix} - 0.25 \\begin{pmatrix} -4 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 5 \\end{pmatrix}$\n",
    "\n",
    "$ w_{t =2} =  \\begin{pmatrix} 1 \\\\ 5 \\end{pmatrix} - 0.25 \\begin{pmatrix} -2 \\\\ 2 \\end{pmatrix} + 0.5 \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 5 \\end{pmatrix}$\n",
    "\n",
    "Keeping this in mind, we can apply it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb413f-a01e-45f9-9a5c-c62b55184af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5400a62d-00a8-43d1-9f9d-41a28037fc98",
   "metadata": {},
   "source": [
    "#### Steepest Gradient Descent\n",
    "\n",
    "The steepest gradient descent method is one that optimizes the way we get to global minima by calculating the highest decrease in the gradient of the error term by calculating the vector perpendicular to the error plane.\n",
    "\n",
    "$\\epsilon (w) = \\epsilon(w_1, w_2) = w_1^3 - 2w_1^2 + w_2^3+ 3w_2^2-8$\n",
    "\n",
    "$\\nabla \\epsilon (w_1, w_2) = \\begin{pmatrix} {w_1} \\\\ {w_2} \\end{pmatrix} = \\begin{pmatrix} {3w_1^2 - 4w_1} \\\\ {3w_2^2+6w_2} \\end{pmatrix} $\n",
    "\n",
    "We find d, **the direction of descent**, which is perpendicular to the direction of ascent, hence we $* -1$\n",
    "\n",
    "$d = -\\nabla \\epsilon (w_1, w_2)$\n",
    "\n",
    "**Now**\n",
    "\n",
    "Given an initial starting $w_0 = \\begin{pmatrix} {1} \\\\ {-1} \\end{pmatrix}$\n",
    "\n",
    "$d = -\\begin{pmatrix} {-1} \\\\ {-3} \\end{pmatrix} $\n",
    "\n",
    "Then we update\n",
    "$ w_{T=t+1} = w_{T = t} + \\lambda d$, giving us: \n",
    "\n",
    "$w + \\lambda d = \\begin{pmatrix} {1 + \\lambda} \\\\ {-1 + 3\\lambda} \\end{pmatrix}$\n",
    "\n",
    "$\\nabla \\epsilon (w + \\lambda d) = \\begin{pmatrix} {3(1+\\lambda)^2-4(1+\\lambda)} \\\\ {3(-1+3\\lambda)^2+6(-1+3\\lambda)} \\end{pmatrix}$\n",
    "\n",
    "**Then, differentiating w.r.t to $\\lambda$ to find optimal $\\lambda$**\n",
    "\n",
    "$\\epsilon ' (\\lambda) = \\nabla \\epsilon (w + \\lambda d)^Td = \\nabla \\epsilon (w + \\lambda d)^T\\begin{pmatrix} {1} \\\\ {3} \\end{pmatrix} = 3(1+\\lambda)^2 -4(1+\\lambda)+9(-1+3\\lambda)^2+18(-1+3\\lambda) $\n",
    "\n",
    "Then solving for $\\epsilon'(\\lambda) = 0$, we get: \n",
    "\n",
    "$ \\lambda = \\frac 1 3, - \\frac 5 {14}$\n",
    "\n",
    "We update the weights accordingly, allowing us to find the optimal weights:\n",
    "\n",
    "$ w_1 = w_0 + \\lambda d = \\begin{pmatrix} {\\frac 4 3} \\\\ {0} \\end{pmatrix}$\n",
    "\n",
    "Then sub this back into our original to get the gradient of this minimum: \n",
    "\n",
    "$ \\nabla \\epsilon (w_1) = \\begin{pmatrix} {0} \\\\ {30} \\end{pmatrix}$\n",
    "\n",
    "First iteration is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1b85b-ade8-4083-aad6-94f952d3331b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5467cbe2-83f9-437b-a19c-e88e252ec1e3",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent\n",
    "\n",
    "So far, the gradient descent we have done is only for two weight terms. However, for large neural networks, where features (and hence number of weights) might be extremely large, this is alot of computation for gradient descent!\n",
    "\n",
    "This is where stochastic gradient descent comes in. Stochastic gradient descent chooses 1 sample for a single training step (mini-batch allows a subset) since our samples might have redundencies (Similar data points). \n",
    "\n",
    "This is good for data with many parameters where gradient descent is not computationally feasible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb47762-2f4d-4003-9788-68f27a59b9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a18a004-f926-475b-81d4-a5523e891e7f",
   "metadata": {},
   "source": [
    "#### Newton's Method of Gradient Descent\n",
    "\n",
    "Remember our original method of finding our root using the newton method is: \n",
    "\n",
    "$w_{n+1} = w_n - \\frac {f'(w_n)} {f''(w_n)}$\n",
    "\n",
    "Translating this into matrix form for our gradient descent:\n",
    "\n",
    "$w_{n+1} = w_n - (\\nabla^2\\epsilon (w_n))^{-1}\\nabla\\epsilon(w_n)$\n",
    "\n",
    "Unlike the Gradient Descent Method, this algorithm uses way less number of steps to reach optima, but is quite inconvenient to compute as the Hessian and its inverse has to be calculated on every iteration, so its computationally expensive, it scales on a $O(n^3)$ complexity compare to $O(n)$ for the simple gradient descent. Therefore it comes at a tradeoff.\n",
    "\n",
    "It is also highly dependent on initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa983e6-455e-460c-bca0-dc4aa3959741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66969313-a33a-489f-81e7-6ccc35b0b668",
   "metadata": {},
   "source": [
    "#### Quasi-Newton Methods of Gradient Descent\n",
    "\n",
    "A better method will be some of the quasi-newton methods, which comes up with approximations that \n",
    "* BFGS (Broyden-Fletcher-Goldfarb-Shanno) update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047e172-96a7-495c-88af-991d46cb5f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
