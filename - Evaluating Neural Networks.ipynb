{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Errors\n",
    "\n",
    "There are different way of calculating errors. Of the most common, they are classified into error metrics for regression and classification problems. These are also called \"loss functions\" as it calculates how much the prediction differents from the actual value.\n",
    "\n",
    "#### Regression Error Metrics\n",
    "\n",
    "##### Mean Squared Error (MSE) \n",
    "\n",
    "${MSE}$ = $ \\frac{1}{n} \\sum \\limits _{i=1} ^{n} ({Y_i} - \\hat{Y_i})^2 $\n",
    "\n",
    "where predicted = $\\hat{Y}$, actual = ${Y}$\n",
    "\n",
    "##### Root Mean Squared Error (RMSE)\n",
    "\n",
    "${RMSE}$ = $ \\frac{1}{n} \\sqrt {\\sum \\limits _{i=1} ^{n} ({Y_i} - \\hat{Y_i})^2 } $\n",
    "\n",
    "where predicted = $\\hat{Y}$, actual = ${Y}$\n",
    "\n",
    "##### Mean Absolute Error (MAE)\n",
    "\n",
    "${MAE}$ = $ \\frac{1}{n} \\sum \\limits _{i=1} ^{n} |{Y_i} - \\hat{Y_i}| $\n",
    "\n",
    "where predicted = $\\hat{Y}$, actual = ${Y}$\n",
    "\n",
    "#### Classification Error Metrics\n",
    "\n",
    "#### 1. Binary Classification \n",
    "\n",
    "Prediction of where the output can either be one or the other. Formula can be found online, complicated, so not covered here.\n",
    "\n",
    "* Binary Cross Entropy \n",
    "* Sigmoid function\n",
    "* Hinge Loss\n",
    "\n",
    "#### 2. Multi-class Classification \n",
    "\n",
    "* Multi-class Cross Entropy\n",
    "* Softmax Function\n",
    "* Kullback-Liebler Divergence (Relative Entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluations\n",
    "\n",
    "<img src='media/simple_nn/classification_error_metrics.png' width=\"300px\"/>\n",
    "\n",
    "##### Recall \n",
    "\n",
    "$Recall$ = $\\frac{TP}{TP+FN}$\n",
    "\n",
    "##### Precision \n",
    "\n",
    "$Precision$ = $\\frac{TP}{TP+FP}$\n",
    "\n",
    "##### F1 Score\n",
    "\n",
    "$F1$ = $\\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
