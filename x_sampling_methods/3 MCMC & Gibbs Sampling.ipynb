{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc558d4-3b83-4d06-aef1-9ed0938fed13",
   "metadata": {},
   "source": [
    "### Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64cb535-a5f2-4883-ac2b-709ba0be7f10",
   "metadata": {},
   "source": [
    "A Markov chain or Markov process is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. In a diagram, this will look something like: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06bd7e-961b-4ffc-a172-2420b01e56cb",
   "metadata": {},
   "source": [
    "<img src = \"markov.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef52708-344c-4040-903f-94759a7095ba",
   "metadata": {},
   "source": [
    "Hence to generalise this, a state at time $S_n$ will be\n",
    "\n",
    "$S_n = P^nS_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e772e6-39e8-43cb-882e-f809b964b833",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "[Markov Chain and Transition Matrices](https://www.youtube.com/watch?v=1GKtfgwf3ig) | Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff68351-f5ea-461f-96e4-84207fae98eb",
   "metadata": {},
   "source": [
    "### Stationary Distribution of a Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b674d6-c23a-484b-8aa4-45f270a26481",
   "metadata": {},
   "source": [
    "The stationary distribution of a Markov chain describes the distribution of Xt after a sufficiently long time that the distribution of Xt does not change any longer. That is \n",
    "\n",
    "$ X_1 \\rightarrow X_2 \\rightarrow X_3 \\rightarrow ... \\rightarrow X_t \\rightarrow X_{t+1} \\rightarrow X_{t+2} $\n",
    "\n",
    "Eventually we will get to values of $X_n$ that follows a static distribution e.g. $X_t ... X_{t+6}$ We then throw away anything before $X_t$ (Also called burn-in values) and take these values to be a simulation to our static distribution\n",
    "\n",
    "Basically - Is there a vector of starting probabilities such that when we arrive at the distribution, it stays constant/static? If the markov chain arrives at a certain state, it has a tendency to stay in that state. i.e. $P(X_{t+1} = S) = P(X_t = S)$\n",
    "\n",
    "Where $\\pi$ is the vector of starting probabilities and $P$ is the transition matrix\n",
    "\n",
    "solve $\\pi P=\\pi$ \n",
    "\n",
    "for $\\pi$\n",
    "\n",
    "which is essentially the same as finding the eigenvector for $AX=\\lambda X$ \n",
    "where the eigenvalue is $\\lambda = 1$\n",
    "\n",
    "**References**\\\n",
    "[Stationary Distribution of a Markov Chain](https://www.youtube.com/watch?v=4sXiCxZDrTU) | Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed7b92f-ed1b-4b69-9814-b29339acbb43",
   "metadata": {},
   "source": [
    "### Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534042a2-db06-4558-bbf0-b890bd0b0f07",
   "metadata": {},
   "source": [
    "MCMC Is a collection of different methods and algorithms. But the general idea: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644fc78-1f56-4a87-83ba-a09504325d1d",
   "metadata": {},
   "source": [
    "Solves the issue in *Accept and Reject Sampling* where lets say we sample a value on $g$, and we get to a sample that very closely approximates $f$, we dont use this information for our next sampling, but instead, we draw a fresh random sample from $g$ to approximate $f$. This is not ideal in cases where $f$ has a peak, as shown in the graph in the notebook on *Accept and Reject Sampling*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d674a-129f-4f34-abd4-6f4409539f14",
   "metadata": {},
   "source": [
    "Bringing it in again, lets say we sample $g$ (the normal dist) and get a point ~0.9. This is very close to our power distribution and is therefore *accepted* (using the accept reject sampling method, which determines this as $\\frac {f} {Mg} $). However, we dont use this information in the next sampling and instead draw a fresh sample that doesnt depend on info gained in the last, for example, sampling a point at -2, instead of somewhere near the peak, say 0.7. MCMC aims to solve this issue by bringing in the context of previous sampling stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92edf7b8-347d-4b6d-8532-318cb0685a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = np.random.normal(size = (10000,))\n",
    "f = np.random.power(1.5, size = (10000, ))\n",
    "\n",
    "nhist = plt.hist(g, bins = 50)\n",
    "phist = plt.hist(f, bins = 50)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac197f-93aa-4e03-988d-ba7f9e6bdc86",
   "metadata": {},
   "source": [
    "Our goal will be to arrive at a stationary distribution such that it models our stationary distribution - with probability density function $f$ well enough through a series of markov chain simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c01545-b5b7-4ba9-b0e6-04bfa5349477",
   "metadata": {},
   "source": [
    "There a few MCMC algorithms that will allow us to arrive at the stationary distribution eventually, such as :\n",
    "1. The Metropolis Hastings Algorithm \n",
    "2. Gibbs Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d5e3c-6872-48f8-9264-bde76f1b8b89",
   "metadata": {},
   "source": [
    "So to sum up, in real world situations where our distributions are irregular, it will be very inefficient to sample our distributions using methods such as AR or IT sampling (for reason stated in the notebooks), so we should use MCMC methods as it allows us to take into consideration previous sampling time steps in order to sample our data. (Make our samples dependent on each other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ef9cc-ab6f-4a3b-b7cf-408026704f0e",
   "metadata": {},
   "source": [
    "#### Metropolis Hastings Algorithm\n",
    "\n",
    "1. Sample from an easier distribution such that the current sample depends on the previous sample, i.e. $g(x_{t+1}|x_t)$ \n",
    "* What this is saying is: Look at our previous sample, center our distribution at $x_t$, then sample the next candidate from that distribution. Then continue this process.\n",
    "\n",
    "Take note that this is different from the **Metropolis Algorithm**, which the candidate distribution has a *symmetric distribution*, which means there is an equally likely chance that $x_{t+1}$ is sampled from above or below the $x_t$ value. In the **Metropolis-Hastings Algorithm**, the candidate distribution is asymmetric.\n",
    "\n",
    "2. Accept $x_{t+1}$ with some acceptance probability $A(X_t \\rightarrow X_{t+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494d879-d690-4d26-ba9e-7c9aa29728cd",
   "metadata": {},
   "source": [
    "###  Gibbs sampling \n",
    "$\\theta_1, \\theta_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ea00f-1b3b-4de4-af9c-e4431a9640b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (audrii)",
   "language": "python",
   "name": "kedro_audrii"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
